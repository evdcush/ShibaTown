{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDetection\n",
    "\"Get Started\" tutorial:\n",
    "https://mmdetection.readthedocs.io/en/latest/get_started.html\n",
    "\n",
    "### Setup\n",
    "I use a pyenv-managed venv for development.\n",
    "I do not use conda, nor did I use MMLab's `mim` to install `mmdet`,\n",
    "nor did I install from source.\n",
    "\n",
    "I decided to simply `pip install mmdet`.\n",
    "\n",
    "Let's see how this goes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the installation\n",
    "They provide some example files to run an inference demo.\n",
    "\n",
    "These files are directly available if you installed from source:\n",
    "\n",
    "```\n",
    "python demo/image_demo.py demo/demo.jpg rtmdet_tiny_8xb32-300e_coco.py \\\n",
    "--weights rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth \\\n",
    "--device cpu\n",
    "```\n",
    "\n",
    "\n",
    "Otherwise you are directed to use `mim` to download these demo files, eg:\n",
    "\n",
    "```\n",
    "mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest .\n",
    "```\n",
    "\n",
    "Since we used none of these methods for installation, \n",
    "let's just see what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import mmdet\n",
    "print(mmdet.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package mmdet:\n",
      "\n",
      "NAME\n",
      "    mmdet - # Copyright (c) OpenMMLab. All rights reserved.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    apis (package)\n",
      "    datasets (package)\n",
      "    engine (package)\n",
      "    evaluation (package)\n",
      "    models (package)\n",
      "    registry\n",
      "    structures (package)\n",
      "    testing (package)\n",
      "    utils (package)\n",
      "    version\n",
      "    visualization (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    digit_version(version_str: str, length: int = 4)\n",
      "        Convert a version string into a tuple of integers.\n",
      "        \n",
      "        This method is usually used for comparing two versions. For pre-release\n",
      "        versions: alpha < beta < rc.\n",
      "        \n",
      "        Args:\n",
      "            version_str (str): The version string.\n",
      "            length (int): The maximum number of version levels. Defaults to 4.\n",
      "        \n",
      "        Returns:\n",
      "            tuple[int]: The version info in digits (integers).\n",
      "\n",
      "DATA\n",
      "    __all__ = ['__version__', 'version_info', 'digit_version']\n",
      "    version_info = (3, 2, 0)\n",
      "\n",
      "VERSION\n",
      "    3.2.0\n",
      "\n",
      "FILE\n",
      "    /home/evan-cushing/.pyenv/versions/3.11.6/envs/3116/lib/python3.11/site-packages/mmdet/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mmdet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation, pt deux\n",
    "Okay, through default `pip` installation, mmdet was deeply borked.\n",
    "It was absolutely unable to run, always returning the error:\n",
    "\n",
    "```\n",
    "ModuleNotFoundError: No module named 'mmcv._ext'\n",
    "```\n",
    "\n",
    "The problem seems be with `mmcv`.\n",
    "You cannot \"just install it\" with `pip`.\n",
    "You have to install the correct target package for your system.\n",
    "\n",
    "Refer to this:\n",
    "\n",
    "https://mmcv.readthedocs.io/en/latest/get_started/installation.html#install-with-pip\n",
    "\n",
    "Now:\n",
    "\n",
    "```\n",
    "pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "pip install mmengine\n",
    "pip install mmdet mmpretrain\n",
    "```\n",
    "\n",
    "Now confirm `mmdet` is not fricking borked; in an interpreter:\n",
    "\n",
    "```\n",
    "from mmdet import apis\n",
    "```\n",
    "\n",
    "Should now \"just work\".\n",
    "\n",
    "Sheesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet import apis, datasets, engine, evaluation, models, registry\n",
    "from mmdet import structures, testing, utils, visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.engine import hooks, optimizers, runner, schedulers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package mmdet.engine in mmdet:\n",
      "\n",
      "NAME\n",
      "    mmdet.engine - # Copyright (c) OpenMMLab. All rights reserved.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    hooks (package)\n",
      "    optimizers (package)\n",
      "    runner (package)\n",
      "    schedulers (package)\n",
      "\n",
      "FILE\n",
      "    /home/evan-cushing/.pyenv/versions/3.11.6/envs/3116/lib/python3.11/site-packages/mmdet/engine/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR\n",
    "It's DETR time now.\n",
    "\n",
    "Let's see what it takes to get their DETR working.\n",
    "\n",
    "We'll be referencing:\n",
    "https://github.com/open-mmlab/mmdetection/tree/main/configs/detr\n",
    "\n",
    "And build out from there.\n",
    "\n",
    "Let's start with their \"official\" (trained) DETR config:\n",
    "`configs/detr/detr_r50_8xb2-150e_coco.py`\n",
    "\n",
    "https://github.com/open-mmlab/mmdetection/blob/main/configs/detr/detr_r50_8xb2-150e_coco.py\n",
    "\n",
    "Now, the question is, can we simply copy-paste the configs and work directly with mmdet imports?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _base_/default_runtime.py\n",
    "# https://github.com/open-mmlab/mmdetection/blob/main/configs/_base_/default_runtime.py\n",
    "\n",
    "default_scope = 'mmdet'\n",
    "\n",
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='DetVisualizationHook'))\n",
    "\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    ")\n",
    "\n",
    "vis_backends = [dict(type='LocalVisBackend')]\n",
    "visualizer = dict(\n",
    "    type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')\n",
    "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n",
    "\n",
    "log_level = 'INFO'\n",
    "load_from = None\n",
    "resume = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _base/datasets/coco_detection.py\n",
    "# https://github.com/open-mmlab/mmdetection/blob/main/configs/_base_/datasets/coco_detection.py\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'CocoDataset'\n",
    "#data_root = 'data/coco/'\n",
    "data_root = '/home/evan-cushing/Data/coco/'\n",
    "\n",
    "# Example to use different file client\n",
    "# Method 1: simply set the data root and let the file I/O module\n",
    "# automatically infer from prefix (not support LMDB and Memcache yet)\n",
    "\n",
    "# data_root = 's3://openmmlab/datasets/detection/coco/'\n",
    "\n",
    "# Method 2: Use `backend_args`, `file_client_args` in versions before 3.0.0rc6\n",
    "# backend_args = dict(\n",
    "#     backend='petrel',\n",
    "#     path_mapping=dict({\n",
    "#         './data/': 's3://openmmlab/datasets/detection/',\n",
    "#         'data/': 's3://openmmlab/datasets/detection/'\n",
    "#     }))\n",
    "backend_args = None\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=backend_args),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=backend_args),\n",
    "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "    # If you don't have a gt annotation, delete the pipeline\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor'))\n",
    "]\n",
    "train_dataloader = dict(\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file='annotations/instances_train2017.json',\n",
    "        data_prefix=dict(img='train2017/'),\n",
    "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "        pipeline=train_pipeline,\n",
    "        backend_args=backend_args))\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file='annotations/instances_val2017.json',\n",
    "        data_prefix=dict(img='val2017/'),\n",
    "        test_mode=True,\n",
    "        pipeline=test_pipeline,\n",
    "        backend_args=backend_args))\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "val_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=data_root + 'annotations/instances_val2017.json',\n",
    "    metric='bbox',\n",
    "    format_only=False,\n",
    "    backend_args=backend_args)\n",
    "test_evaluator = val_evaluator\n",
    "\n",
    "# inference on test dataset and\n",
    "# format the output results for submission.\n",
    "# test_dataloader = dict(\n",
    "#     batch_size=1,\n",
    "#     num_workers=2,\n",
    "#     persistent_workers=True,\n",
    "#     drop_last=False,\n",
    "#     sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "#     dataset=dict(\n",
    "#         type=dataset_type,\n",
    "#         data_root=data_root,\n",
    "#         ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "#         data_prefix=dict(img='test2017/'),\n",
    "#         test_mode=True,\n",
    "#         pipeline=test_pipeline))\n",
    "# test_evaluator = dict(\n",
    "#     type='CocoMetric',\n",
    "#     metric='bbox',\n",
    "#     format_only=True,\n",
    "#     ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "#     outfile_prefix='./work_dirs/coco_detection/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs/detr/detr_r50_8xb2-150e_coco.py\n",
    "# https://github.com/open-mmlab/mmdetection/blob/main/configs/detr/detr_r50_8xb2-150e_coco.py\n",
    "\n",
    "#_base_ = [\n",
    "#    '../_base_/datasets/coco_detection.py', '../_base_/default_runtime.py'\n",
    "#]\n",
    "\n",
    "model = dict(\n",
    "    type='DETR',\n",
    "    num_queries=100,\n",
    "    data_preprocessor=dict(\n",
    "        type='DetDataPreprocessor',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        bgr_to_rgb=True,\n",
    "        pad_size_divisor=1),\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(3, ),\n",
    "        frozen_stages=1,\n",
    "        norm_cfg=dict(type='BN', requires_grad=False),\n",
    "        norm_eval=True,\n",
    "        style='pytorch',\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
    "    neck=dict(\n",
    "        type='ChannelMapper',\n",
    "        in_channels=[2048],\n",
    "        kernel_size=1,\n",
    "        out_channels=256,\n",
    "        act_cfg=None,\n",
    "        norm_cfg=None,\n",
    "        num_outs=1),\n",
    "    encoder=dict(  # DetrTransformerEncoder\n",
    "        num_layers=6,\n",
    "        layer_cfg=dict(  # DetrTransformerEncoderLayer\n",
    "            self_attn_cfg=dict(  # MultiheadAttention\n",
    "                embed_dims=256,\n",
    "                num_heads=8,\n",
    "                dropout=0.1,\n",
    "                batch_first=True),\n",
    "            ffn_cfg=dict(\n",
    "                embed_dims=256,\n",
    "                feedforward_channels=2048,\n",
    "                num_fcs=2,\n",
    "                ffn_drop=0.1,\n",
    "                act_cfg=dict(type='ReLU', inplace=True)))),\n",
    "    decoder=dict(  # DetrTransformerDecoder\n",
    "        num_layers=6,\n",
    "        layer_cfg=dict(  # DetrTransformerDecoderLayer\n",
    "            self_attn_cfg=dict(  # MultiheadAttention\n",
    "                embed_dims=256,\n",
    "                num_heads=8,\n",
    "                dropout=0.1,\n",
    "                batch_first=True),\n",
    "            cross_attn_cfg=dict(  # MultiheadAttention\n",
    "                embed_dims=256,\n",
    "                num_heads=8,\n",
    "                dropout=0.1,\n",
    "                batch_first=True),\n",
    "            ffn_cfg=dict(\n",
    "                embed_dims=256,\n",
    "                feedforward_channels=2048,\n",
    "                num_fcs=2,\n",
    "                ffn_drop=0.1,\n",
    "                act_cfg=dict(type='ReLU', inplace=True))),\n",
    "        return_intermediate=True),\n",
    "    positional_encoding=dict(num_feats=128, normalize=True),\n",
    "    bbox_head=dict(\n",
    "        type='DETRHead',\n",
    "        num_classes=80,\n",
    "        embed_dims=256,\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss',\n",
    "            bg_cls_weight=0.1,\n",
    "            use_sigmoid=False,\n",
    "            loss_weight=1.0,\n",
    "            class_weight=1.0),\n",
    "        loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n",
    "        loss_iou=dict(type='GIoULoss', loss_weight=2.0)),\n",
    "    # training and testing settings\n",
    "    train_cfg=dict(\n",
    "        assigner=dict(\n",
    "            type='HungarianAssigner',\n",
    "            match_costs=[\n",
    "                dict(type='ClassificationCost', weight=1.),\n",
    "                dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),\n",
    "                dict(type='IoUCost', iou_mode='giou', weight=2.0)\n",
    "            ])),\n",
    "    test_cfg=dict(max_per_img=100))\n",
    "\n",
    "# train_pipeline, NOTE the img_scale and the Pad's size_divisor is different\n",
    "# from the default setting in mmdet.\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='RandomChoice',\n",
    "        transforms=[[\n",
    "            dict(\n",
    "                type='RandomChoiceResize',\n",
    "                scales=[(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n",
    "                        (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n",
    "                        (736, 1333), (768, 1333), (800, 1333)],\n",
    "                keep_ratio=True)\n",
    "        ],\n",
    "                    [\n",
    "                        dict(\n",
    "                            type='RandomChoiceResize',\n",
    "                            scales=[(400, 1333), (500, 1333), (600, 1333)],\n",
    "                            keep_ratio=True),\n",
    "                        dict(\n",
    "                            type='RandomCrop',\n",
    "                            crop_type='absolute_range',\n",
    "                            crop_size=(384, 600),\n",
    "                            allow_negative_crop=True),\n",
    "                        dict(\n",
    "                            type='RandomChoiceResize',\n",
    "                            scales=[(480, 1333), (512, 1333), (544, 1333),\n",
    "                                    (576, 1333), (608, 1333), (640, 1333),\n",
    "                                    (672, 1333), (704, 1333), (736, 1333),\n",
    "                                    (768, 1333), (800, 1333)],\n",
    "                            keep_ratio=True)\n",
    "                    ]]),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "train_dataloader = dict(dataset=dict(pipeline=train_pipeline))\n",
    "\n",
    "# optimizer\n",
    "optim_wrapper = dict(\n",
    "    type='OptimWrapper',\n",
    "    optimizer=dict(type='AdamW', lr=0.0001, weight_decay=0.0001),\n",
    "    clip_grad=dict(max_norm=0.1, norm_type=2),\n",
    "    paramwise_cfg=dict(\n",
    "        custom_keys={'backbone': dict(lr_mult=0.1, decay_mult=1.0)}))\n",
    "\n",
    "# learning policy\n",
    "#max_epochs = 150\n",
    "max_epochs = 2\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop', max_epochs=max_epochs, val_interval=1)\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='MultiStepLR',\n",
    "        begin=0,\n",
    "        end=max_epochs,\n",
    "        by_epoch=True,\n",
    "        milestones=[100],\n",
    "        gamma=0.1)\n",
    "]\n",
    "\n",
    "# NOTE: `auto_scale_lr` is for automatically scaling LR,\n",
    "# USER SHOULD NOT CHANGE ITS VALUES.\n",
    "# base_batch_size = (8 GPUs) x (2 samples per GPU)\n",
    "auto_scale_lr = dict(base_batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndefault_scope\\ndefault_hooks\\nenv_cfg\\nvis_backends\\nvisualizer\\nlog_processor\\nlog_level\\nload_from\\nresume\\n\\ndataset_type\\ndata_root\\nbackend_args\\ntrain_pipeline\\ntest_pipeline\\ntrain_dataloader\\nval_dataloader\\ntest_dataloader\\nval_evaluator\\ntest_evaluator\\n\\nmodel\\ntrain_pipeline\\ntrain_dataloader\\noptim_wrapper\\nmax_epochs\\ntrain_cfg\\nval_cfg\\ntest_cfg\\nparam_scheduler\\nauto_scale_lr\\n\\n----\\n\\ndict(\\n    model=model,\\n    train_pipeline=train_pipeline,\\n    train_dataloader=train_dataloader,\\n    optim_wrapper=optim_wrapper,\\n    max_epochs=max_epochs,\\n    train_cfg=train_cfg,\\n    val_cfg=val_cfg,\\n    test_cfg=test_cfg,\\n    param_scheduler=param_scheduler,\\n    auto_scale_lr=auto_scale_lr,\\n    backend_args=backend_args,\\n    test_pipeline=test_pipeline,\\n    val_dataloader=val_dataloader,\\n    test_dataloader=test_dataloader,\\n    val_evaluator=val_evaluator,\\n    test_evaluator=test_evaluator,\\n    default_scope=default_scope,\\n    default_hooks=default_hooks,\\n    env_cfg=env_cfg,\\n    vis_backends=vis_backends,\\n    visualizer=visualizer,\\n    log_processor=log_processor,\\n    log_level=log_level,\\n    load_from=load_from,\\n    resume=resume,\\n)\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "default_scope\n",
    "default_hooks\n",
    "env_cfg\n",
    "vis_backends\n",
    "visualizer\n",
    "log_processor\n",
    "log_level\n",
    "load_from\n",
    "resume\n",
    "\n",
    "dataset_type\n",
    "data_root\n",
    "backend_args\n",
    "train_pipeline\n",
    "test_pipeline\n",
    "train_dataloader\n",
    "val_dataloader\n",
    "test_dataloader\n",
    "val_evaluator\n",
    "test_evaluator\n",
    "\n",
    "model\n",
    "train_pipeline\n",
    "train_dataloader\n",
    "optim_wrapper\n",
    "max_epochs\n",
    "train_cfg\n",
    "val_cfg\n",
    "test_cfg\n",
    "param_scheduler\n",
    "auto_scale_lr\n",
    "\n",
    "----\n",
    "\n",
    "dict(\n",
    "    model=model,\n",
    "    train_pipeline=train_pipeline,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optim_wrapper=optim_wrapper,\n",
    "    max_epochs=max_epochs,\n",
    "    train_cfg=train_cfg,\n",
    "    val_cfg=val_cfg,\n",
    "    test_cfg=test_cfg,\n",
    "    param_scheduler=param_scheduler,\n",
    "    auto_scale_lr=auto_scale_lr,\n",
    "    backend_args=backend_args,\n",
    "    test_pipeline=test_pipeline,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    val_evaluator=val_evaluator,\n",
    "    test_evaluator=test_evaluator,\n",
    "    default_scope=default_scope,\n",
    "    default_hooks=default_hooks,\n",
    "    env_cfg=env_cfg,\n",
    "    vis_backends=vis_backends,\n",
    "    visualizer=visualizer,\n",
    "    log_processor=log_processor,\n",
    "    log_level=log_level,\n",
    "    load_from=load_from,\n",
    "    resume=resume,\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    model=model,\n",
    "    train_pipeline=train_pipeline,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optim_wrapper=optim_wrapper,\n",
    "    max_epochs=max_epochs,\n",
    "    train_cfg=train_cfg,\n",
    "    val_cfg=val_cfg,\n",
    "    test_cfg=test_cfg,\n",
    "    param_scheduler=param_scheduler,\n",
    "    auto_scale_lr=auto_scale_lr,\n",
    "    backend_args=backend_args,\n",
    "    test_pipeline=test_pipeline,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    val_evaluator=val_evaluator,\n",
    "    test_evaluator=test_evaluator,\n",
    "    default_scope=default_scope,\n",
    "    default_hooks=default_hooks,\n",
    "    env_cfg=env_cfg,\n",
    "    vis_backends=vis_backends,\n",
    "    visualizer=visualizer,\n",
    "    log_processor=log_processor,\n",
    "    log_level=log_level,\n",
    "    load_from=load_from,\n",
    "    resume=resume,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it\n",
    "Okay, after browsing the `mmdet` package and subpackages (particularly\n",
    "`mmdet.apis` and `mmdet.engine`), it's clear that you need to write your own\n",
    "code for execution of training.\n",
    "\n",
    "But how?\n",
    "\n",
    "Well, taking a look at:\n",
    "\n",
    "https://github.com/open-mmlab/mmdetection/blob/main/tools/train.py\n",
    "\n",
    "It's clear that we must now use `mmengine`!\n",
    "\n",
    "## MMEngine\n",
    "\n",
    "Let's first check out what we can get from the `mmengine` package,\n",
    "then reference mmdet's `tools/train.py`.\n",
    "\n",
    "Here's a snippet of `help(mmengine)`:\n",
    "\n",
    "```\n",
    "PACKAGE CONTENTS\n",
    "* mmengine\n",
    "  * _strategy\n",
    "    - base\n",
    "    - colossalai\n",
    "    - deepspeed\n",
    "    - distributed\n",
    "    - fsdp\n",
    "    - single_device\n",
    "    - utils\n",
    "  * analysis\n",
    "    - complexity_analysis\n",
    "    - jit_analysis\n",
    "    - jit_handles\n",
    "    - print_helper\n",
    "  * config\n",
    "    - config\n",
    "    - lazy\n",
    "    - utils\n",
    "  * dataset\n",
    "    - base_dataset\n",
    "    - dataset_wrapper\n",
    "    - sampler\n",
    "    - utils\n",
    "  * device\n",
    "    - utils\n",
    "  * dist\n",
    "    - dist\n",
    "    - utils\n",
    "  * evaluator\n",
    "    - evaluator\n",
    "    - metric\n",
    "    - utils\n",
    "  * fileio\n",
    "    * backends\n",
    "      - base\n",
    "      - http_backend\n",
    "      - lmdb_backend\n",
    "      - local_backend\n",
    "      - memcached_backend\n",
    "      - petrel_backend\n",
    "      - registry_utils\n",
    "    - file_client\n",
    "    * handlers\n",
    "      - base\n",
    "      - json_handler\n",
    "      - pickle_handler\n",
    "      - registry_utils\n",
    "      - yaml_handler\n",
    "    - io\n",
    "    - parse\n",
    "  * hooks\n",
    "    - checkpoint_hook\n",
    "    - early_stopping_hook\n",
    "    - ema_hook\n",
    "    - empty_cache_hook\n",
    "    - hook\n",
    "    - iter_timer_hook\n",
    "    - logger_hook\n",
    "    - naive_visualization_hook\n",
    "    - param_scheduler_hook\n",
    "    - profiler_hook\n",
    "    - runtime_info_hook\n",
    "    - sampler_seed_hook\n",
    "    - sync_buffer_hook\n",
    "    - test_time_aug_hook\n",
    "  * hub\n",
    "    - hub\n",
    "  * infer\n",
    "    - infer\n",
    "  * logging\n",
    "    - history_buffer\n",
    "    - logger\n",
    "    - message_hub\n",
    "  * model\n",
    "    - averaged_model\n",
    "    * base_model\n",
    "      - base_model\n",
    "      - data_preprocessor\n",
    "    - base_module\n",
    "    - efficient_conv_bn_eval\n",
    "    - test_time_aug\n",
    "    - utils\n",
    "    - weight_init\n",
    "    * wrappers\n",
    "      - distributed\n",
    "      - fully_sharded_distributed\n",
    "      - seperate_distributed\n",
    "      - utils\n",
    "  * optim\n",
    "    * optimizer\n",
    "      - amp_optimizer_wrapper\n",
    "      - apex_optimizer_wrapper\n",
    "      - base\n",
    "      - builder\n",
    "      - default_constructor\n",
    "      - optimizer_wrapper\n",
    "      - optimizer_wrapper_dict\n",
    "      - zero_optimizer\n",
    "    * scheduler\n",
    "      - lr_scheduler\n",
    "      - momentum_scheduler\n",
    "      - param_scheduler\n",
    "  * registry\n",
    "    - build_functions\n",
    "    - default_scope\n",
    "    - registry\n",
    "    - root\n",
    "    - utils\n",
    "  * runner\n",
    "    - _flexible_runner\n",
    "    - activation_checkpointing\n",
    "    - amp\n",
    "    - base_loop\n",
    "    - checkpoint\n",
    "    - log_processor\n",
    "    - loops\n",
    "    - priority\n",
    "    - runner\n",
    "    - utils\n",
    "  * structures\n",
    "    - base_data_element\n",
    "    - instance_data\n",
    "    - label_data\n",
    "    - pixel_data\n",
    "  * testing\n",
    "    * _internal\n",
    "      - distributed\n",
    "    - compare\n",
    "    - runner_test_case\n",
    "  * utils\n",
    "    * dl_utils\n",
    "      - collect_env\n",
    "      - hub\n",
    "      - misc\n",
    "      - parrots_wrapper\n",
    "      - setup_env\n",
    "      - time_counter\n",
    "      - torch_ops\n",
    "      - trace\n",
    "      - visualize\n",
    "    - manager\n",
    "    - misc\n",
    "    - package_utils\n",
    "    - path\n",
    "    - progressbar\n",
    "    - progressbar_rich\n",
    "    - timer\n",
    "    - version_utils\n",
    "  - version\n",
    "  * visualization\n",
    "    - utils\n",
    "    - vis_backend\n",
    "    - visualizer\n",
    "\n",
    "DATA\n",
    "    DATASETS\n",
    "    DATA_SAMPLERS\n",
    "    EVALUATOR\n",
    "    FUNCTIONS\n",
    "    HOOKS\n",
    "    INFERENCERS\n",
    "    LOOPS\n",
    "    METRICS\n",
    "    MODELS\n",
    "    MODEL_WRAPPERS\n",
    "    OPTIMIZERS\n",
    "    OPTIM_WRAPPERS\n",
    "    OPTIM_WRAPPER_CONSTRUCTORS\n",
    "    PARAM_SCHEDULERS\n",
    "    RUNNERS\n",
    "    RUNNER_CONSTRUCTORS\n",
    "    STRATEGIES\n",
    "    TASK_UTILS\n",
    "    VISBACKENDS\n",
    "    VISUALIZERS\n",
    "    WEIGHT_INITIALIZERS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all registries.\n",
    "from mmengine import (\n",
    "    DATASETS, DATA_SAMPLERS, EVALUATOR, FUNCTIONS, HOOKS,\n",
    "    INFERENCERS, LOOPS, METRICS, MODELS, MODEL_WRAPPERS, OPTIMIZERS,\n",
    "    OPTIM_WRAPPERS, OPTIM_WRAPPER_CONSTRUCTORS, PARAM_SCHEDULERS, RUNNERS,\n",
    "    RUNNER_CONSTRUCTORS, STRATEGIES, TASK_UTILS, VISBACKENDS, VISUALIZERS,\n",
    "    WEIGHT_INITIALIZERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "from mmdet.utils import setup_cache_size_limit_of_dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: None): {'model': {'type': 'DETR', 'num_queries': 100, 'data_preprocessor': {'type': 'DetDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'bgr_to_rgb': True, 'pad_size_divisor': 1}, 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (3,), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': False}, 'norm_eval': True, 'style': 'pytorch', 'init_cfg': {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}}, 'neck': {'type': 'ChannelMapper', 'in_channels': [2048], 'kernel_size': 1, 'out_channels': 256, 'act_cfg': None, 'norm_cfg': None, 'num_outs': 1}, 'encoder': {'num_layers': 6, 'layer_cfg': {'self_attn_cfg': {'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1, 'batch_first': True}, 'ffn_cfg': {'embed_dims': 256, 'feedforward_channels': 2048, 'num_fcs': 2, 'ffn_drop': 0.1, 'act_cfg': {'type': 'ReLU', 'inplace': True}}}}, 'decoder': {'num_layers': 6, 'layer_cfg': {'self_attn_cfg': {'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1, 'batch_first': True}, 'cross_attn_cfg': {'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1, 'batch_first': True}, 'ffn_cfg': {'embed_dims': 256, 'feedforward_channels': 2048, 'num_fcs': 2, 'ffn_drop': 0.1, 'act_cfg': {'type': 'ReLU', 'inplace': True}}}, 'return_intermediate': True}, 'positional_encoding': {'num_feats': 128, 'normalize': True}, 'bbox_head': {'type': 'DETRHead', 'num_classes': 80, 'embed_dims': 256, 'loss_cls': {'type': 'CrossEntropyLoss', 'bg_cls_weight': 0.1, 'use_sigmoid': False, 'loss_weight': 1.0, 'class_weight': 1.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}}, 'train_cfg': {'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'ClassificationCost', 'weight': 1.0}, {'type': 'BBoxL1Cost', 'weight': 5.0, 'box_format': 'xywh'}, {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}]}}, 'test_cfg': {'max_per_img': 100}}, 'train_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [(400, 1333), (500, 1333), (600, 1333)], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}], 'train_dataloader': {'dataset': {'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [(400, 1333), (500, 1333), (600, 1333)], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]}}, 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'clip_grad': {'max_norm': 0.1, 'norm_type': 2}, 'paramwise_cfg': {'custom_keys': {'backbone': {'lr_mult': 0.1, 'decay_mult': 1.0}}}}, 'max_epochs': 2, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 2, 'val_interval': 1}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'MultiStepLR', 'begin': 0, 'end': 2, 'by_epoch': True, 'milestones': [100], 'gamma': 0.1}], 'auto_scale_lr': {'base_batch_size': 16}, 'backend_args': None, 'test_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'val_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': '/home/evan-cushing/Data/coco/', 'ann_file': 'annotations/instances_val2017.json', 'data_prefix': {'img': 'val2017/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'CocoDataset', 'data_root': '/home/evan-cushing/Data/coco/', 'ann_file': 'annotations/instances_val2017.json', 'data_prefix': {'img': 'val2017/'}, 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')}], 'backend_args': None}}, 'val_evaluator': {'type': 'CocoMetric', 'ann_file': '/home/evan-cushing/Data/coco/annotations/instances_val2017.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None}, 'test_evaluator': {'type': 'CocoMetric', 'ann_file': '/home/evan-cushing/Data/coco/annotations/instances_val2017.json', 'metric': 'bbox', 'format_only': False, 'backend_args': None}, 'default_scope': 'mmdet', 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 50}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 1}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'visualization': {'type': 'DetVisualizationHook'}}, 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'DetLocalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}], 'name': 'visualizer'}, 'log_processor': {'type': 'LogProcessor', 'window_size': 50, 'by_epoch': True}, 'log_level': 'INFO', 'load_from': None, 'resume': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
